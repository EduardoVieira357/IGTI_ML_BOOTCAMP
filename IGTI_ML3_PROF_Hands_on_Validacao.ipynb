{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIl-k3lr8Qiv"
   },
   "source": [
    "# **Hands-on Validação**\n",
    "\n",
    "---\n",
    "\n",
    "Validação com sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SN6weYKF8N8v"
   },
   "source": [
    "Neste *hands on*, vamos aprofundar um pouco mais nos processos de validação usados pra medir a performance de algoritmos de machine learning. Aqui, vamos focar na tarefa de classificação como exemplo, mas nosso foco é no processo de validação. \n",
    "\n",
    "Vamos avaliar 3 tipos diferentes de validação e discutir vantagens e desvantagens de cada uma delas. Os tipos de validação são: \n",
    "\n",
    "* **Treino-Teste**: Esse tipo de validação consiste em separar, aleatoriamente, uma porção da base de dados para servir como conjunto de teste. Dessa forma, o algoritmo tem acesso somente a parte dos dados para construir o modelo e sua performance é avaliada no conjunto de dados que esteve escondido (teste) no processo. \n",
    "\n",
    "* **Validação Cruzada**: Neste tipo de validação, ao invés de separar em um conjunto fixo de treinamento e outro de teste, o processo é ampliado para todo dado disponível faça parte do treino e do teste em algum momento. Assim, definimos um número de partições para o dado e cada uma das partições é usada como teste em algum ponto. Ao final, consideramos a média das execuções para avaliar a performance do algoritmo.\n",
    "\n",
    "* **Leave-one-out**: Este tipo de validação consiste em uma extensão da validação cruzada, em que se considera o número de partições igual à quantidade de amostras disponíveis no dado. Assim, cada conjunto de teste é sempre composto por uma única amostra do dado, ao passo que o restante das amostras é usada para treinamento do algoritmo.\n",
    "\n",
    "\n",
    "É importante destacar que nosso interesse principal ao avaliar um algoritmo de machine learning é encontrar um algoritmo que tenha boa capacidade de **generalização**, ou seja, tem boa performance em dados que não foram vistos durante a etapa de treinamento. Todos os tipos de validação anterior, nos ajudam a avaliar essa capacidade, testando a solucão encontrada em um conjunto de dados **novo** para o algoritmo. Dentre os tipos de avaliação mencionados, tipicamente, a validação cruzada é mais amplamente usada, pois combina a maior parte das vantagens que veremos na sequência.\n",
    "\n",
    "Mais informações sobre esses tipos de validação podem ser encontradas na documentação do sklearn, no link a seguir.\n",
    "\n",
    "*   <a href = https://scikit-learn.org/stable/modules/cross_validation.html> Validação no sklearn </a>\n",
    "\n",
    "\n",
    "Vamos utilizar a base de dados **diabetes.csv** </a> que pode ser encontrada no OpenML em: https://www.openml.org/d/37. Essa base descreve o problema de predizer o resultado positivo ou negativo de um teste para diabetes aplicado em um conjunto específico de pacientes na Índia. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5wwHwTQ8N8v"
   },
   "source": [
    "### *Importando* bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "i_5G2bRaHU8i"
   },
   "outputs": [],
   "source": [
    "import pandas as pd #biblioteca para manipulação de dados\n",
    "import numpy as np #biblioteca para utilizacao de vetores e matrizes\n",
    "import matplotlib.pyplot as plt #bibloteca para plotar graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ufc7rjN0Hbb7",
    "outputId": "2283b6a1-b443-49b7-f181-a5c9569e49c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#liberando acesso do colab aos arquivos no drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9aBPfZwHjwK"
   },
   "source": [
    "### Carregamento dos dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "FTLPdcSaHsIo"
   },
   "outputs": [],
   "source": [
    "#lendo o csv que contem a base de dados e armazanando em um df\n",
    "df = pd.read_csv('/content/gdrive/My Drive/DADOS/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Yw9wSFNd8N8w",
    "outputId": "05f8406a-518f-4341-e3ca-b3f9fcb15a16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
       "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
       "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
       "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
       "4     0   137    40    35   168  43.1  2.288   33  tested_positive"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imprimindo as 5 primeiras linhas do df para confirmação\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFaZnXnAIonA"
   },
   "source": [
    "*   preg: number of times pregnant\n",
    "*   plas: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "*   pres: Diastolic blood pressure (mm Hg)\n",
    "*   skin: Triceps skin fold thickness (mm)\n",
    "*   insu: 2-Hour serum insulin (mu U/ml)\n",
    "*   mass: Body mass index (weight in kg/(height in m)^2)\n",
    "*   pedi: Diabetes pedigree function\n",
    "*   age: Age (years)\n",
    "*   class: Class variable (tested_positive or tested_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "d_lxVAD-8N86",
    "outputId": "91a29720-41ee-42ed-bc54-c6bbaa811775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras e Features: (768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Verificando o numero de amostras (linhas) e features (colunas) do dataset. \n",
    "print('Amostras e Features:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "MILEATwd8N9A",
    "outputId": "ce83cef1-ad2c-48fc-baab-e271afe26376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Index(['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age', 'class'], dtype='object') \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   preg    768 non-null    int64  \n",
      " 1   plas    768 non-null    int64  \n",
      " 2   pres    768 non-null    int64  \n",
      " 3   skin    768 non-null    int64  \n",
      " 4   insu    768 non-null    int64  \n",
      " 5   mass    768 non-null    float64\n",
      " 6   pedi    768 non-null    float64\n",
      " 7   age     768 non-null    int64  \n",
      " 8   class   768 non-null    object \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 54.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Verificando quais são os tipos das features   #### O CERTO QUAL É O NOME DAS COLUNAS(FEATURES)\n",
    "print('\\n',df.columns,'\\n')  #### PROFESSOR SOMENTE LISTA OS NOMES DAS COLUNAS\n",
    "\n",
    "df.info()  ################ EUDARDO MOSTRANDO OS TIPOS DE FEATURES, TIPOS DOS DADOS DE CADA COLUNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "sINtIJzAhTuK",
    "outputId": "b3a56826-551d-48e6-b99f-41ec9b2e85b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): 6, dtype('float64'): 2, dtype('O'): 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = dict(df.dtypes.value_counts())  ######## contar a quantidade e tipos\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2aq9YGyJ_YN"
   },
   "source": [
    "### Pré processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD1KwfP08N9E"
   },
   "source": [
    "Nesse problema, o único atributo categórico é a classe. Alguns modelos podem ter dificuldade de lidar com esse atributo. Nesse caso, precisamos transformar os valores de \"tested_negative\" e \"tested_positivo\" para 0 e 1.\n",
    "\n",
    "Para isso, vamos fazer uma função bem simples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "RbSaDmfQqdfj",
    "outputId": "ba4294fa-3b9f-4940-c15a-a3d704f1ea86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criando um dicionario de dados para o mapeamento\n",
    "name_to_class = {\n",
    "    'tested_negative': 0,\n",
    "    'tested_positive': 1\n",
    "}\n",
    "\n",
    "#substituindo os valores categóricos pelo mapeamento\n",
    "df['class'] = df['class'].map(name_to_class)\n",
    "\n",
    "#check\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J94oUYW8N9Q"
   },
   "source": [
    "Uma outra etapa importante do pré-processamento consiste na avaliação de dados faltantes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "fOQWr4kR8N9R",
    "outputId": "ac5dd511-0246-4bfd-a0eb-fb4874b1df85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres  ...        pedi         age       class\n",
       "count  768.000000  768.000000  768.000000  ...  768.000000  768.000000  768.000000\n",
       "mean     3.845052  120.894531   69.105469  ...    0.471876   33.240885    0.348958\n",
       "std      3.369578   31.972618   19.355807  ...    0.331329   11.760232    0.476951\n",
       "min      0.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n",
       "25%      1.000000   99.000000   62.000000  ...    0.243750   24.000000    0.000000\n",
       "50%      3.000000  117.000000   72.000000  ...    0.372500   29.000000    0.000000\n",
       "75%      6.000000  140.250000   80.000000  ...    0.626250   41.000000    1.000000\n",
       "max     17.000000  199.000000  122.000000  ...    2.420000   81.000000    1.000000\n",
       "\n",
       "[8 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisando o resumo da base\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mH3u8WT8N9f"
   },
   "source": [
    "Os modelos implementados no sklearn recebem como entrada para a modelagam um ou mais arrays. Dessa forma, precisamos modificar o df original para que seja possível a modelagem correta. \n",
    "\n",
    "Para isso, vamos separar o label das amostras, armazenar o nome das features - já que os arrays não fazem isso - e depois retirar a coluna de labels do df original. Em seguida, vamos converter o df para array usando o numpy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "TLl1SoI7jRvF",
    "outputId": "8fd5a170-7dec-4c89-9134-2993098f4571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0]\n",
      "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
      " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
      " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
      " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
      " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n"
     ]
    }
   ],
   "source": [
    "################## EDUARDO MELHORANDO A SITUAÇÃO - sem deletar ou motificar o DF\n",
    "\n",
    "labels_edu = np.array(df['class'])\n",
    "data_edu =   np.array(df.drop('class',axis=1))\n",
    "print(labels_edu)\n",
    "print(data_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "WZ3jLCuEOfbJ"
   },
   "outputs": [],
   "source": [
    "# armazenando os labels em um array\n",
    "labels = np.array(df['class'])\n",
    "\n",
    "# salvando a ordem das features\n",
    "feature_list = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Q5wIxGj68N9g",
    "outputId": "7786079d-5824-4918-bd80-1716b4f8233c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age'], dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removendo a coluna de labels do df original\n",
    "df = df.drop('class', axis = 1)\n",
    "\n",
    "# check\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "H24By9Vf8N9k"
   },
   "outputs": [],
   "source": [
    "# convertendo df para array\n",
    "data = np.array(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsWyYltEv0fc"
   },
   "source": [
    "### Treino-Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY6_Mcme8N9o"
   },
   "source": [
    "Em uma das aulas anteriores já passamos por essa etapa, porém com menos detalhes. Agora, vamos avaliar com um pouco mais de cuidado as estratégias de validação. \n",
    "\n",
    "Para usar a a estratégia de validação *treino-teste*, precisamos apenas separar uma parte dos nossos dados para conjunto de treino e a parte restante para conjunto de teste. \n",
    "\n",
    "Para fazer essa separação, vamos usar a função <a href = http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html> train_test_split</a> do sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "lZH_kTIxwZwD"
   },
   "outputs": [],
   "source": [
    "# importar train_test_split do scikitlearn \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "9E3DFwvIwqA5"
   },
   "outputs": [],
   "source": [
    "# aplicando a funcao train_test_split para separar os conjuntos de treino e \n",
    "# teste segundo uma porcentagem de separação definida. \n",
    "train_data1, test_data1, train_labels1, test_labels1 = train_test_split(data, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "yVvtNFY8wwbv"
   },
   "outputs": [],
   "source": [
    "train_data2, test_data2, train_labels2, test_labels2 = train_test_split(data, labels, test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Ews_1IMu8N9p"
   },
   "outputs": [],
   "source": [
    "train_data3, test_data3, train_labels3, test_labels3 = train_test_split(data, labels, test_size = 0.35, random_state = 42)  ### 35%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYsqiOG18N9v"
   },
   "source": [
    "### Modegalem com Treino-Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpkQtbyW8N9w"
   },
   "source": [
    "Não existe uma regra pré-definida para o tamanho do conjunto de teste. Tipicamente usamos entre 20% e 40% da base de dados, dependendo do número total de amostras disponíveis. \n",
    "\n",
    "Após separar a base de dados em treino e teste, o próximo passo é executar o modelo escolhido e avaliar o resultado. \n",
    "\n",
    "Nesse momento estamos menos preocupados em comparar algoritmos distintos para escolher o melhor mas sim em entender a melhor estratégia para montar o processo de validação. Assim, vamos aplicar somente um dos algoritmos que vimos anteriormente e focar nos resultados que podemos obter com os diferentes métodos de validação.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MglFMlLLbggA"
   },
   "source": [
    "# Random Forest Classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qjPEqNfbmtk"
   },
   "source": [
    "Vamos agora modelar o nosso problema utilizando o Random Forest Classifier!\n",
    "\n",
    "Esse modelo é um dos mais utilizados tanto na sua versão de regressor quanto para sua versão de classificador e, em geral, apresenta ótimos resultados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7LrKgJhb8N-K"
   },
   "outputs": [],
   "source": [
    "# importar o modelo Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# treinando o modelo \n",
    "classifier1 = RandomForestClassifier(n_estimators= 10, random_state=42).fit(train_data1, train_labels1)  ### 10 arvores dentro da floresta\n",
    "classifier2 = RandomForestClassifier(n_estimators= 10, random_state=42).fit(train_data2, train_labels2)\n",
    "classifier3 = RandomForestClassifier(n_estimators= 10, random_state=42).fit(train_data3, train_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "o86GOgTY8N-P",
    "outputId": "9e10dc5f-19a4-4430-d451-8d967a763943"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Real  Previsto\n",
       "0     0         0\n",
       "1     0         0\n",
       "2     0         0\n",
       "3     0         0\n",
       "4     0         1\n",
       "5     0         0\n",
       "6     0         0\n",
       "7     0         1\n",
       "8     0         1\n",
       "9     0         1"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicando o modelo treinado para a previsão do resultado do teste\n",
    "predictions1_labels = classifier1.predict(test_data1)\n",
    "predictions2_labels = classifier2.predict(test_data2)\n",
    "predictions3_labels = classifier3.predict(test_data3)\n",
    "\n",
    "# Exibindo dataframe com valores 10 reais e suas respectivas previsões\n",
    "p = pd.DataFrame({'Real': test_labels3, 'Previsto': predictions3_labels})  \n",
    "p.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "MkGPfvlEyCoj",
    "outputId": "763b39ac-641b-4b4d-96d8-d0b50d70ddb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 1 1 0 0]\n",
      "[1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1\n",
      " 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1\n",
      " 1 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions1_labels)\n",
    "print(predictions2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "iQVCNXmiMKAi",
    "outputId": "afefec1d-11bc-49d0-a9fc-6d2c89e0aeb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia\n",
      " 0.7395833333333334\n",
      "\n",
      "Acurácia\n",
      " 0.7447916666666666\n",
      "\n",
      "Acurácia\n",
      " 0.758364312267658\n"
     ]
    }
   ],
   "source": [
    "# importar biblioteca para calculo de métricas\n",
    "from sklearn import metrics \n",
    "\n",
    "print('\\nAcurácia\\n', metrics.accuracy_score(test_labels1, predictions1_labels)) \n",
    "print('\\nAcurácia\\n', metrics.accuracy_score(test_labels2, predictions2_labels)) \n",
    "print('\\nAcurácia\\n', metrics.accuracy_score(test_labels3, predictions3_labels)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3Lg2GaIMb7U"
   },
   "source": [
    "Aqui podemos observar algumas coisas a respeito dessa estratégia de validação. \n",
    "\n",
    "Os dois primeiros conjuntos de teste possuem exatamente o mesmo tamanho (25% da base de dados), mas os resultados de acúracia foram diferentes. O segundo conjunto teve uma acurácia superior. A única diferença entre os dois conjuntos de teste foi a aleatoriedade na seleção. \n",
    "\n",
    "Aqui fica muito claro que este método é muito sujeito ao viés de seleção. É difícil dizer que o segundo modelo é melhor que o primeiro, apesar do resultado superior. Isso acontece porque esse resultado pode ter sido fruto somente de uma seleção mais favorável. De maneira informal, podemos pensar como se o conjunto de teste, aleatoriamente escolhido para o segundo conjunto de dados, possuía as amostras mais fáceis de serem acertadas. \n",
    "\n",
    "Além disso, observamos também que o terceiro conjunto obteve um resultado melhor que os anteriores. Aqui também nossa capacidade de tomar uma decisão é limitada pelo método. O nosso terceiro conjunto de teste tinha tamanho 30% da base de dados. Um primeiro pensamento aqui poderia ser um resultado pior, já que a base de treinamento acabaria sendo menor, tendo um teste um pouco maior. Porém, estamos sujeitos novamente ao viés da seleção, por mais que ela seja aleatória. Ainda assim, podemos ver outro ponto negativo dessa estratégia, que é: quanto maior nosso dado de teste, menos dados temos para a modelagem. \n",
    "\n",
    "Você consegue pensar em uma situação em que essa estratégia pode ser muito ruim? R.: Dados desbalanceados!\n",
    "\n",
    "Na verdade, essa estratégia raramente é usada para se tirar uma conclusão sobre a qualidade do modelo. No fim, ela acaba sendo só um primeiro passo para construir as estratégias mais elaboradas de validação que veremos a seguir.\n",
    "\n",
    "Antes porém, vamos olhar também as outras métricas que já conhecemos. Faça o exercício de comparar os resultados entre os três conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "j3XYU8C_clmb",
    "outputId": "1da1a423-002e-45aa-c2b6-3a685a9117a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão\n",
      " [[97 26]\n",
      " [24 45]]\n",
      "Matriz de Confusão\n",
      " [[100  19]\n",
      " [ 30  43]]\n",
      "Matriz de Confusão\n",
      " [[153  28]\n",
      " [ 37  51]]\n",
      "\n",
      "Acurácia Balanceada por classe\n",
      " 0.72039589961117\n",
      "\n",
      "Acurácia Balanceada por classe\n",
      " 0.7146886151720963\n",
      "\n",
      "Acurácia Balanceada por classe\n",
      " 0.7124246609743847\n",
      "\n",
      "Precision\n",
      " 0.6338028169014085\n",
      "\n",
      "Precision\n",
      " 0.6935483870967742\n",
      "\n",
      "Precision\n",
      " 0.6455696202531646\n",
      "\n",
      "Recall\n",
      " 0.6521739130434783\n",
      "\n",
      "Recall\n",
      " 0.589041095890411\n",
      "\n",
      "Recall\n",
      " 0.5795454545454546\n",
      "\n",
      "F1\n",
      " 0.6428571428571428\n",
      "\n",
      "F1\n",
      " 0.6370370370370372\n",
      "\n",
      "F1\n",
      " 0.6107784431137726\n",
      "\n",
      "AUCROC\n",
      " 0.72039589961117\n",
      "\n",
      "AUCROC\n",
      " 0.7146886151720963\n",
      "\n",
      "AUCROC\n",
      " 0.7124246609743847\n"
     ]
    }
   ],
   "source": [
    "# importar biblioteca para calculo de métricas\n",
    "from sklearn import metrics \n",
    "\n",
    "#avaliando o modelo\n",
    "print('Matriz de Confusão\\n', metrics.confusion_matrix(test_labels1, predictions1_labels)) \n",
    "print('Matriz de Confusão\\n', metrics.confusion_matrix(test_labels2, predictions2_labels)) \n",
    "print('Matriz de Confusão\\n', metrics.confusion_matrix(test_labels3, predictions3_labels)) \n",
    "\n",
    "print('\\nAcurácia Balanceada por classe\\n', metrics.balanced_accuracy_score(test_labels1, predictions1_labels)) \n",
    "print('\\nAcurácia Balanceada por classe\\n', metrics.balanced_accuracy_score(test_labels2, predictions2_labels)) \n",
    "print('\\nAcurácia Balanceada por classe\\n', metrics.balanced_accuracy_score(test_labels3, predictions3_labels)) \n",
    "\n",
    "print('\\nPrecision\\n', metrics.precision_score(test_labels1, predictions1_labels)) \n",
    "print('\\nPrecision\\n', metrics.precision_score(test_labels2, predictions2_labels)) \n",
    "print('\\nPrecision\\n', metrics.precision_score(test_labels3, predictions3_labels)) \n",
    "\n",
    "print('\\nRecall\\n', metrics.recall_score(test_labels1, predictions1_labels)) \n",
    "print('\\nRecall\\n', metrics.recall_score(test_labels2, predictions2_labels)) \n",
    "print('\\nRecall\\n', metrics.recall_score(test_labels3, predictions3_labels)) \n",
    "\n",
    "print('\\nF1\\n', metrics.f1_score(test_labels1, predictions1_labels)) \n",
    "print('\\nF1\\n', metrics.f1_score(test_labels2, predictions2_labels)) \n",
    "print('\\nF1\\n', metrics.f1_score(test_labels3, predictions3_labels)) \n",
    "\n",
    "print('\\nAUCROC\\n', metrics.roc_auc_score(test_labels1, predictions1_labels))\n",
    "print('\\nAUCROC\\n', metrics.roc_auc_score(test_labels2, predictions2_labels))\n",
    "print('\\nAUCROC\\n', metrics.roc_auc_score(test_labels3, predictions3_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ekq770pckaJp"
   },
   "source": [
    "Resuminho...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "ie2ZqN7pka5m",
    "outputId": "5e02c9c0-ba17-4e6a-c89b-b0ff0ca5e631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80       123\n",
      "           1       0.63      0.65      0.64        69\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.72      0.72      0.72       192\n",
      "weighted avg       0.74      0.74      0.74       192\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       119\n",
      "           1       0.69      0.59      0.64        73\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.73      0.71      0.72       192\n",
      "weighted avg       0.74      0.74      0.74       192\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.82       181\n",
      "           1       0.65      0.58      0.61        88\n",
      "\n",
      "    accuracy                           0.76       269\n",
      "   macro avg       0.73      0.71      0.72       269\n",
      "weighted avg       0.75      0.76      0.75       269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification Report\\n', metrics.classification_report(test_labels1, predictions1_labels)) \n",
    "print('\\nClassification Report\\n', metrics.classification_report(test_labels2, predictions2_labels)) \n",
    "print('\\nClassification Report\\n', metrics.classification_report(test_labels3, predictions3_labels)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUbi-TvIRRje"
   },
   "source": [
    "## Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmxU8wv7u0RJ"
   },
   "source": [
    "Agora voltamos nosso interesse para uma estratégia de validação um pouco mais complexa e útil, chamada de validação cruzada.\n",
    "\n",
    "Vamos usar a mesma base de dados do exemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "OLOOuouARV7o",
    "outputId": "023a34e7-3c74-49e8-d6ca-87b3606ded6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age\n",
       "0     6   148    72    35     0  33.6  0.627   50\n",
       "1     1    85    66    29     0  26.6  0.351   31\n",
       "2     8   183    64     0     0  23.3  0.672   32\n",
       "3     1    89    66    23    94  28.1  0.167   21\n",
       "4     0   137    40    35   168  43.1  2.288   33"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lembre-se que já removemos a coluna com a classe anteriormente\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGlCrLWEz6El"
   },
   "source": [
    "Na estratégia anterior, fizemos a separação do dado em conjunto de treinamento e conjunto de teste. Aqui não vamos fazer isso de maneira explícita. Vamos usar a função <a href = https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html> cross_val_score </a> para nos ajudar no processo. \n",
    "\n",
    "Essa função será responsável por controlar a separação dos conjuntos de treino e teste, além da iteração por cada um deles computando as métricas desejadas. \n",
    "\n",
    "Ainda podemos fazer essa iteração manualmente se for desejado, mas o uso da função simplifica o processo e otimiza algumas etapas, bastando para isso definir o número de conjuntos de validação que desejamos usar. \n",
    "\n",
    "Vamos fazer um primeiro exemplo na sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rY6Fp_vryk9g",
    "outputId": "731d33a0-05e3-4104-9cbf-8f86d7e8c403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74025974, 0.69480519, 0.77922078, 0.79738562, 0.74509804])"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "classifier_cv = RandomForestClassifier(n_estimators= 10, random_state=42) ### RadomForestClassifier\n",
    "\n",
    "scores_cv = cross_val_score(classifier_cv, data, labels, cv=5)\n",
    "scores_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9Yc0y_vGzVmV",
    "outputId": "c12ee1d2-bdb3-4b4f-8bea-005f50dd66fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.75 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores_cv.mean(), scores_cv.std() * 2))  ### desvio padrão pequeno, tudo ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKd70pBK0Q26"
   },
   "source": [
    "Tipicamente, o score retornado é sempre o padrão do algoritmo escolhido. Para algoritmos de classificação, a grande maioria retorna por padrão a acurácia do algoritmo. \n",
    "\n",
    "Essa métrica de avaliação pode ser substituído conforme desejado, bastando passar para a função uma outra opção de score. Vamos usar mais algumas métricas que já conhecemos a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "ufNvVUUR0eke",
    "outputId": "1f60b9b8-c2d3-4475-f5ff-87a59a0d50f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 (+/- 0.07)\n",
      "Precision: 0.70 (+/- 0.18)\n",
      "Recall: 0.52 (+/- 0.12)\n",
      "F1: 0.59 (+/- 0.10)\n"
     ]
    }
   ],
   "source": [
    "scores_cv_accuracy = cross_val_score(classifier_cv, data, labels, cv=5) ### eduardo\n",
    "scores_cv_precision = cross_val_score(classifier_cv, data, labels, cv=5, scoring='precision')\n",
    "scores_cv_recall = cross_val_score(classifier_cv, data, labels, cv=5, scoring='recall')\n",
    "scores_cv_f1 = cross_val_score(classifier_cv, data, labels, cv=5, scoring='f1')\n",
    "\n",
    "##### desvio padrão mostra quanto os dados estão distantes da média ###\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_cv_accuracy.mean(), scores_cv_accuracy.std() * 2))  ### eduardo\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_cv_precision.mean(), scores_cv_precision.std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_cv_recall.mean(), scores_cv_recall.std() * 2))\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_cv_f1.mean(), scores_cv_f1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "HRRFMsDOGc2h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR8aQLy79gqx"
   },
   "source": [
    "#### Como avaliar os vários conjuntos?\n",
    "\n",
    "Na estratégia da validação cruzada, podemos imaginar como se fossem várias etapas de treino e teste, em que cada execução é uma partição diferente da base de dados. Nesse caso, temos como resultado não apenas uma medição, mas sim tantas quantas forem o número de partições selecionadas. Ao invés de olhar separadamente cada uma delas, tipicamente usamos a média de cada métrica sobre todos os conjuntos. Assim, temos uma ideia geral da performance do algoritmo, considerando todo o processo de validação. \n",
    "\n",
    "Além disso, é interessante também olha o desvio padrão desse conjunto de medidas. Se temos um desvio muito grande, ou seja, alguns conjuntos deram bons resultados e outros um resultado ruim, isso pode ser um indicativo de algo deve ser repensado. Podemos, por exemplo, querer penalizar um algoritmo se isso acontece. Ainda, pode ser interessante avaliar se existe alguma característica no dado em que a separação puramente aleatória não seja suficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjjCYQSYZnD3"
   },
   "source": [
    "#### Quantos conjuntos de validação usar?\n",
    "\n",
    "No exemplo anterior usamos uma validação cruzada com 5 conjuntos de validação, evidenciada pelo parâmetro cv=5. Não existe um número ideal definido ou uma regra exata para ajudar a escolher esse parâmetro. \n",
    "\n",
    "Frequentemente se usa 3, 5 e 10 como boas opções. Nada impede que sejam usados números maiores ou menores, o importante aqui é objetivo: avaliar a capacidade de generalização do método. \n",
    "\n",
    "Dois fatores importantes a serem levados em consideração ao escolher o número de conjuntos de validação:\n",
    "\n",
    "* número de amostras disponíveis na base de dados: se nossa base de dados é muito pequena (como no nosso exemplo de hoje, menos de 1000 amostras), separar em poucos conjuntos pode ser ruim. Quanto menos conjuntos, maior o tamanho de cada um deles e consequentemente menos dado para treinamento do modelo.\n",
    "* complexidade computacional do algoritmo escolhido: se o algoritmo escolhido é muito custoso computacionalmente, podemos não querer escolher um número de conjuntos muito grande. Isso aumentaria muito o número de execuções para um algoritmo que já é custoso. Isso pode ser especialmente relevante se a base de dados é muito grande. \n",
    "\n",
    "Vamos refazer o nosso exemplo, mas dessa vez considerando cv=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "H4MSpvL9_AiK",
    "outputId": "71922dba-f3e1-4f85-be82-8ef0ba136b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.76 (+/- 0.09)\n",
      "Precision: 0.74 (+/- 0.24)\n",
      "Recall: 0.54 (+/- 0.14)\n",
      "F1: 0.61 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "classifier_cv = RandomForestClassifier(n_estimators= 10, random_state=42)\n",
    "\n",
    "scores_cv = cross_val_score(classifier_cv, data, labels, cv=10) ##### accuracy é o padrão\n",
    "scores_cv_precision = cross_val_score(classifier_cv, data, labels, cv=10, scoring='precision')\n",
    "scores_cv_recall = cross_val_score(classifier_cv, data, labels, cv=10, scoring='recall')\n",
    "scores_cv_f1 = cross_val_score(classifier_cv, data, labels, cv=10, scoring='f1')\n",
    "\n",
    "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores_cv.mean(), scores_cv.std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_cv_precision.mean(), scores_cv_precision.std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_cv_recall.mean(), scores_cv_recall.std() * 2))\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_cv_f1.mean(), scores_cv_f1.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "DwcgICWzJs0g",
    "outputId": "2da2ea96-f3d9-4a70-8949-628b959285ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7012987 , 0.80519481, 0.72727273, 0.7012987 , 0.77922078,\n",
       "       0.77922078, 0.81818182, 0.81818182, 0.73684211, 0.77631579])"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "jpJ3F6dMJvTS",
    "outputId": "07da6989-ba14-4fe4-ab41-3834cb28066a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59090909, 0.92857143, 0.625     , 0.57692308, 0.91666667,\n",
       "       0.75      , 0.84210526, 0.7826087 , 0.65      , 0.71428571])"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "p7h83grS4U9G",
    "outputId": "726b6371-643d-436b-efda-b35b1332f8a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  #### apenas 768 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsQSmaEuANSL"
   },
   "source": [
    "Legal! Obtivemos uma pequena melhora somente aumentando um pouco o número de conjuntos de validação. Um possível motivo é que, com um número maior de conjuntos, temos menos exemplos em cada conjunto de teste e portanto mais amostras para o treinamento. Isso pode favorecer a construção do modelo e consequentemente ter melhores resultados. Se nossa base de dados fosse maior, talvez não teríamos observado esse efeito.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfjAtOCecHZx"
   },
   "source": [
    "#### Lembrete: Obtendo predições individuais\n",
    "\n",
    "Além de avaliar a performance dos algoritmos usando a validação cruzada, podemos estar interessados também em obter as predições propriamente. Para isso, podemos usar a função <a href = https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html> cross_val_predict </a>.\n",
    "\n",
    "Essa função é útil em dois cenários:\n",
    "* Quando queremos visualizar as previsões de alguma forma\n",
    "* Quando queremos usar as previsões para alimentar algum modelo posterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Am6GN1h_El_H"
   },
   "source": [
    "## Variações na Validação Cruzada\n",
    "\n",
    "Até agora vimos uma estratégia de validação cruzada que está entre as mais usadas. Frequentemente essa estratégia é chamada de k-fold, em uma referência a escolha de k conjuntos para particionar o dado. \n",
    "\n",
    "Existem porém alguns cenários em que a estratégia vista até agora pode apresentar alguns problemas. Imagine por exemplo o cenário em que temos um desbalanceamento entre as classes da ordem de 90% de positivos e 10% negativos. Assim, uma seleção aleatória simples pode acabar não sendo adequada, uma vez que podemos ter poucas amostras da classe negativa no teste. Isso também ocorre no cenário multiclasse, especialmente se as classes tiverem prevalências muito diferentes. \n",
    "\n",
    "Para resolver esses casos, existem algumas variações possíveis para validação cruzada. Uma variação muito comumente usada é a validação cruzada estratificada. Nesta variação, a separação entre os conjuntos de treino e teste continua sendo feita aleatoriamente, porém ela preserva a proporção de cada classes nos conjuntos de treino e teste. Assim, se temos um cenário de desbalanceamento, como o descrito anteriormente, em que uma classe tem 90% de prevalência e outra 10%, cada um dos conjuntos criados para validação cruzada irá manter essa proporção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPpW1FwyGMoF"
   },
   "source": [
    "Vamos fazer um exemplo da validação cruzada com estratificação!\n",
    "\n",
    "O sklearn nos permite usar uma estrutura de iterables para facilitar o processo. Assim, ao invés de passar para a função cross_val_score o número de conjuntos de validação que queremos, podemos passar essa estrutura que vai construir a validação no formato desejado.\n",
    "\n",
    "No caso da validação cruzada estratificada, vamos usar a função StratifiedKFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "MrC97lqYGQ71",
    "outputId": "7502ca6c-4b7a-4372-def2-e50ebc241b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.76 (+/- 0.09)\n",
      "Precision: 0.74 (+/- 0.24)\n",
      "Recall: 0.54 (+/- 0.14)\n",
      "F1: 0.61 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "classifier_cv = RandomForestClassifier(n_estimators= 10, random_state=42)\n",
    "\n",
    "cv_strat = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "scores_cv_strat = cross_val_score(classifier_cv, data, labels, cv=cv_strat)\n",
    "scores_cv_strat_precision = cross_val_score(classifier_cv, data, labels, cv=cv_strat, scoring='precision')\n",
    "scores_cv_strat_recall = cross_val_score(classifier_cv, data, labels, cv=cv_strat, scoring='recall')\n",
    "scores_cv_strat_f1 = cross_val_score(classifier_cv, data, labels, cv=cv_strat, scoring='f1')\n",
    "\n",
    "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores_cv_strat.mean(), scores_cv_strat.std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_cv_strat_precision.mean(), scores_cv_strat_precision.std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_cv_strat_recall.mean(), scores_cv_strat_recall.std() * 2))\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_cv_strat_f1.mean(), scores_cv_strat_f1.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD2g-JADPHTb"
   },
   "source": [
    "Como nossa base de dados é mais comportada, não observamos uma variação muito grande no resultado. Porém, essa estratégia pode ser fundamental para avaliar corretamente um modelo, no cenário em que os dados sejam mais desbalanceados e especialmente com multiclasse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZOigHLOnz6S"
   },
   "source": [
    "### Reduzindo ainda mais o viés de seleção\n",
    "\n",
    "Uma das maiores desvantagens que falamos sobre o método de treino-teste é o seu possível viés de seleção, que nos impossibilita de tirar conclusões sobre a capacidade de generalização do algoritmo avaliado.\n",
    "\n",
    "A validação cruzada surge como uma excelente opção nesse cenário. Ao invés de ter um único conjunto de treino e teste, temos vários e mais do que isso, todos as amostras da base em algum momento são avaliadas no teste. \n",
    "\n",
    "Contudo, ainda assim temos um pequeno viés. Uma vez que as partições são criadas, a avalição é feita em cima dessas partições. Como dito anteriormente, sempre olhamos para a média da métrica sobre os vários conjuntos, além do desvio padrão. \n",
    "\n",
    "Uma maneira ainda mais conservadora de avaliar a validação cruzada é realizar esse processo repetidamente. Assim, os conjuntos são aleatorizados várias vezes e ao final temos uma medida ainda mais assertiva da capacidade do método. \n",
    "\n",
    "O sklearn possui um iterable para esse cenário também que você pode testar, como RepeatedKFold e RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quLYbfg3Rg9K"
   },
   "source": [
    "## Leave One Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rig3iX5_G177"
   },
   "source": [
    "Finalmente chegamos na nossa última estratégia de validação, chamada de Leave One Out (LOO). Como já falamos anteriormente, essa estratégia leva a validação cruzada ao máximo, fazendo com que cada exemplo da base de dados seja uma partição de teste. \n",
    "\n",
    "Para usar essa estratégia, temos algumas opções diferentes no sklearn\n",
    "\n",
    "* Fazer cv = número de amostras da base\n",
    "* Usar um iterable KFold e escolher o número de splits igual ao número de amostras da base de dados\n",
    "* Usar um iterable específico para essa estratégias\n",
    "\n",
    "Para o nosso exemplo, vamos escolher o último caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "PbktMKaqPmML",
    "outputId": "a04f8cf2-ca34-4656-b170-4f1ac66acac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.75 (+/- 0.87)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "classifier_cv = RandomForestClassifier(n_estimators= 10, random_state=42)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores_loo = cross_val_score(classifier_cv, data, labels, cv=loo)\n",
    "\n",
    "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores_loo.mean(), scores_loo.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "BA9BMVrGBCaT",
    "outputId": "0a75a39d-45ae-4214-d503-95b2fcdfa722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlqT8y3swNC6"
   },
   "source": [
    "Novamente, devido ao tamanho e comportamento da nossa base de dados, não observamos muita diferença.\n",
    "\n",
    "Um ponto a se destacar sobre a estratégia de LOO é que ela é computacionalmente custosa. Além disso, algumas métricas como precision e recall não são bem definidas, já que temos apenas uma amostra no teste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vd6pIEyPB7zX"
   },
   "source": [
    "**Tipicamente, durante a seleção de modelos se usa a validação cruzada, tomando cuidados para casos de contorno (exemplo: dados desbalanceados) e com número de conjuntos 5 ou 10.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Yvn2Ui9fDyK"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IGTI_ML_PROF_Hands_on_Validacao.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
