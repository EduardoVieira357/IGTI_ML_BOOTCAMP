{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "Zxswp_7dxPI8",
    "outputId": "770147f6-d31c-4cee-e427-8befd477e167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "#gerando as stopwords\n",
    "import nltk  #biblioteca para a análise de textos\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from pprint import pprint  #biblioteca para realizar o \"print\" de forma mais amigável \"pretty-print\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "ooiskYxFNCZL",
    "outputId": "c778f8fb-b4f2-4d3d-c0cd-0e07c4469745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'a' 'o' 'que' 'e' 'é' 'do' 'da' 'em' 'um' 'para' 'com' 'não' 'uma'\n",
      " 'os' 'no' 'se' 'na' 'por' 'mais' 'as' 'dos' 'como' 'mas' 'ao' 'ele' 'das'\n",
      " 'à' 'seu' 'sua' 'ou' 'quando' 'muito' 'nos' 'já' 'eu' 'também' 'só'\n",
      " 'pelo' 'pela' 'até' 'isso' 'ela' 'entre' 'depois' 'sem' 'mesmo' 'aos'\n",
      " 'seus' 'quem' 'nas' 'me' 'esse' 'eles' 'você' 'essa' 'num' 'nem' 'suas'\n",
      " 'meu' 'às' 'minha' 'numa' 'pelos' 'elas' 'qual' 'nós' 'lhe' 'deles'\n",
      " 'essas' 'esses' 'pelas' 'este' 'dele' 'tu' 'te' 'vocês' 'vos' 'lhes'\n",
      " 'meus' 'minhas' 'teu' 'tua' 'teus' 'tuas' 'nosso' 'nossa' 'nossos'\n",
      " 'nossas' 'dela' 'delas' 'esta' 'estes' 'estas' 'aquele' 'aquela'\n",
      " 'aqueles' 'aquelas' 'isto' 'aquilo' 'estou' 'está' 'estamos' 'estão'\n",
      " 'estive' 'esteve' 'estivemos' 'estiveram' 'estava' 'estávamos' 'estavam'\n",
      " 'estivera' 'estivéramos' 'esteja' 'estejamos' 'estejam' 'estivesse'\n",
      " 'estivéssemos' 'estivessem' 'estiver' 'estivermos' 'estiverem' 'hei' 'há'\n",
      " 'havemos' 'hão' 'houve' 'houvemos' 'houveram' 'houvera' 'houvéramos'\n",
      " 'haja' 'hajamos' 'hajam' 'houvesse' 'houvéssemos' 'houvessem' 'houver'\n",
      " 'houvermos' 'houverem' 'houverei' 'houverá' 'houveremos' 'houverão'\n",
      " 'houveria' 'houveríamos' 'houveriam' 'sou' 'somos' 'são' 'era' 'éramos'\n",
      " 'eram' 'fui' 'foi' 'fomos' 'foram' 'fora' 'fôramos' 'seja' 'sejamos'\n",
      " 'sejam' 'fosse' 'fôssemos' 'fossem' 'for' 'formos' 'forem' 'serei' 'será'\n",
      " 'seremos' 'serão' 'seria' 'seríamos' 'seriam' 'tenho' 'tem' 'temos' 'tém'\n",
      " 'tinha' 'tínhamos' 'tinham' 'tive' 'teve' 'tivemos' 'tiveram' 'tivera'\n",
      " 'tivéramos' 'tenha' 'tenhamos' 'tenham' 'tivesse' 'tivéssemos' 'tivessem'\n",
      " 'tiver' 'tivermos' 'tiverem' 'terei' 'terá' 'teremos' 'terão' 'teria'\n",
      " 'teríamos' 'teriam']\n"
     ]
    }
   ],
   "source": [
    "stopWordPortugues = nltk.corpus.stopwords.words('portuguese')\n",
    "print(np.transpose(stopWordPortugues))  ### transpose tranformou vetor coluna para vetor linha, apenas para facilitar a visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "X0XjQ38tf3FO",
    "outputId": "8bb43546-e6cc-48a4-e1a2-3bd582a4f211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' O menino gosta de jogar futebol aos finais de semana.',\n",
      " 'Ele gosta de jogar com seus amigos Marcos e João, mas não gosta de brincar\\n'\n",
      " 'com a irmã Marcela']\n"
     ]
    }
   ],
   "source": [
    "#gerando os tokens de sentenças  #############  sentenças. frases... ATENÇAÕ! não é sempre que o ponto é utilizado como referência\n",
    "sample_text=\"\"\" O menino gosta de jogar futebol aos finais de semana. \n",
    "Ele gosta de jogar com seus amigos Marcos e João, mas não gosta de brincar\n",
    "com a irmã Marcela\"\"\"\n",
    "tokenizacao_sentencas=nltk.sent_tokenize\n",
    "sample_sentence = tokenizacao_sentencas(text=sample_text)\n",
    "pprint(sample_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hq947qkkOpuN",
    "outputId": "521e9610-b4b4-4cc3-9bb8-9712e9165c5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_sentence) ############# duas sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "VZlivgR3g6EF",
    "outputId": "406bc041-b9c5-406b-85f8-1a8bb7610875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O',\n",
      " 'menino',\n",
      " 'gosta',\n",
      " 'de',\n",
      " 'jogar',\n",
      " 'futebol',\n",
      " 'aos',\n",
      " 'finais',\n",
      " 'de',\n",
      " 'semana',\n",
      " '.']\n"
     ]
    }
   ],
   "source": [
    "#tokenização de palavras  ########## palavras\n",
    "sample_sentence='O menino gosta de jogar futebol aos finais de semana.'\n",
    "tokenizacao_palavras=nltk.word_tokenize\n",
    "sample_words = tokenizacao_palavras(text=sample_sentence)\n",
    "pprint(sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "4GhT0e4qNX0u",
    "outputId": "1ee563d4-5796-4806-d717-1505d13c6bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gerando as amostras de stem\n",
    "from nltk.stem import PorterStemmer  #stemização baseado no algoritmo de Porter #### processo de redução \"ao tronco\"..,. porção da palavra\n",
    "from nltk.stem import RSLPStemmer #stemização para o português\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "XYW4BWysQiyx",
    "outputId": "baa31218-517d-40ed-eebf-05869021aae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump\n",
      "jump\n",
      "amor\n",
      "amor\n",
      "am\n",
      "am\n",
      "namor\n",
      "namor\n"
     ]
    }
   ],
   "source": [
    "#gerado stem através do nltk\n",
    "ps=PorterStemmer()\n",
    "stemmer =RSLPStemmer()\n",
    "\n",
    "print(ps.stem('jumping'))\n",
    "print(ps.stem('jumped'))\n",
    "print(stemmer.stem('amoroso')) \n",
    "print(stemmer.stem('amorosa'))\n",
    "print(stemmer.stem('amados'))\n",
    "print(stemmer.stem('amadas'))\n",
    "print(stemmer.stem('namorando'))\n",
    "print(stemmer.stem('namorado'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "BJDrwlnPQ0Qs",
    "outputId": "c3f8c3e7-c9f6-48f1-c173-3feb62b41881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguagens suportadas %s ('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer   # mais indicado para a lingua portuguesa\n",
    "\n",
    "print('Linguagens suportadas %s',SnowballStemmer.languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "BZNfCX1KQ5P0",
    "outputId": "df14c66f-c8a3-41c5-e858-605a26d88b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cas\n",
      "cas\n",
      "cas\n"
     ]
    }
   ],
   "source": [
    "ss = SnowballStemmer(\"portuguese\")\n",
    "print(ss.stem('casado'))\n",
    "print(ss.stem('casarão'))\n",
    "print(ss.stem('casa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZV1Kn5Ao2fF"
   },
   "source": [
    "** ---------------------**Exemplo Bag of Words ---------------------**** **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_idIhbTZqNsV"
   },
   "outputs": [],
   "source": [
    "sentenca=\"O IGTI oferece especializacao em Deep Learning. Deep Learning e utilizado em diversas aplicacoes. As aplicacoes de deep learning sao estudadas nesta especializacao. O IGTI tambem oferece bootcamp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jgmZh9ItwH24"
   },
   "outputs": [],
   "source": [
    "#coloca toda a sentença em lowercase\n",
    "sentenca=sentenca.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "f3RxA_XMun_b",
    "outputId": "c7e7e75a-f448-47d0-96cf-0bcf4bec7e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o igti oferece especializacao em deep learning. deep learning e utilizado em diversas aplicacoes. as aplicacoes de deep learning sao estudadas nesta especializacao. o igti tambem oferece bootcamp\n"
     ]
    }
   ],
   "source": [
    "print(sentenca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "8Ck6OBZzu0p9",
    "outputId": "e0431307-e934-4b5c-9ff6-25cdc145e709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o igti oferece especializacao em deep learning.',\n",
      " 'deep learning e utilizado em diversas aplicacoes.',\n",
      " 'as aplicacoes de deep learning sao estudadas nesta especializacao.',\n",
      " 'o igti tambem oferece bootcamp']\n"
     ]
    }
   ],
   "source": [
    "#tokenização de sentencas\n",
    "tokenizacao_sentencas=nltk.sent_tokenize\n",
    "sample_sentence = tokenizacao_sentencas(text=sentenca)\n",
    "pprint(sample_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aJx79fF7vmD_",
    "outputId": "86c74558-e49b-4a21-f7e3-98124a087f73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'o igti oferece especializacao em deep learning.'"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence[0] #seleciona a primeira sentença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fPXCXPsPvkuv"
   },
   "outputs": [],
   "source": [
    "#tokenização de palavras    ##### o professor fez assim mas poderia tokenizar direto por palavras e não por cada sentença\n",
    "tokenizacao_palavras=nltk.word_tokenize\n",
    "list_words=[]\n",
    "for i in range(len(sample_sentence)):\n",
    "  sample_words = tokenizacao_palavras(text=sample_sentence[i])\n",
    "  list_words.extend(sample_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "UMXwFa1Iw5a2",
    "outputId": "69636938-52ec-4a2b-a6e6-218c8d7ecc53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'igti', 'oferece', 'especializacao', 'em', 'deep', 'learning', '.', 'deep', 'learning', 'e', 'utilizado', 'em', 'diversas', 'aplicacoes', '.', 'as', 'aplicacoes', 'de', 'deep', 'learning', 'sao', 'estudadas', 'nesta', 'especializacao', '.', 'o', 'igti', 'tambem', 'oferece', 'bootcamp']\n"
     ]
    }
   ],
   "source": [
    "print(list_words)  #corpus a ser analisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UdtSSiqMPU1O",
    "outputId": "c91dc6ed-bfc4-4d51-dade-d04c9149ceaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_words)  #### eduardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "N1UYpWC7PVbb",
    "outputId": "09f6e4aa-e716-4f7e-ba77-227483e0c7a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'igti', 'oferece', 'especializacao', 'em', 'deep', 'learning', '.', 'deep', 'learning', 'e', 'utilizado', 'em', 'diversas', 'aplicacoes', '.', 'as', 'aplicacoes', 'de', 'deep', 'learning', 'sao', 'estudadas', 'nesta', 'especializacao', '.', 'o', 'igti', 'tambem', 'oferece', 'bootcamp']\n"
     ]
    }
   ],
   "source": [
    "tokenizacao_palavras=nltk.word_tokenize  ######## eduardo\n",
    "list_words_eduardo = tokenizacao_palavras(text=sentenca)\n",
    "print(list_words_eduardo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "o-WG7H7IPifu",
    "outputId": "47250d64-26c0-4b47-d5fe-4808030ebcba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_words_eduardo) ##### eduardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-44g1nSPirk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "0yZEFwLNxdML"
   },
   "outputs": [],
   "source": [
    "#tokeniza palavras  ################# aqui\n",
    "def tokenizaPalavras(sentenca):\n",
    "  sample_words = tokenizacao_palavras(text=sentenca)\n",
    "  return sample_words\n",
    "\n",
    "\n",
    "#removendo stopwords e criando o BoW\n",
    "def removeStopWords(list_of_words):\n",
    "\n",
    "  my_stop_words=['o','em','as','de','sao','nesta','.','e','a','na','do'] # cria a lista de stopwords\n",
    "  list_cleaned=set(list_of_words)-set(my_stop_words)\n",
    "  return list_cleaned\n",
    "\n",
    "\n",
    "list_words = tokenizaPalavras(sentenca)\n",
    "my_BoW=removeStopWords(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MVp7bYXm2aBS",
    "outputId": "1c45a155-8b0b-4a75-8624-e47b327f7c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diversas', 'learning', 'estudadas', 'deep', 'especializacao', 'aplicacoes', 'utilizado', 'oferece', 'igti', 'bootcamp', 'tambem'}\n"
     ]
    }
   ],
   "source": [
    "print(my_BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "oz6-fmYP6xBX"
   },
   "outputs": [],
   "source": [
    "#Cria o vetor que representa a sentenca na BoW \n",
    "def bagofwords(sentence, words):\n",
    "    sentence_words = tokenizaPalavras(sentence)\n",
    "\n",
    "    # conta a frequência de palavras que estão no vetor do BoW\n",
    "    bag = np.zeros(len(words))\n",
    "    \n",
    "    for sw in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word == sw: \n",
    "                bag[i] += 1\n",
    "                \n",
    "    return np.array(bag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vjDpTNr8SAMI",
    "outputId": "0a118a9a-e195-4a70-98d2-eba4b47db1da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 0. 0. 2. 2. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "sentenca_teste='o igti oferece especializacao em deep learning e o igti oferece bootcamp'\n",
    "print(bagofwords(sentenca_teste,my_BoW))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preparacao_textos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
